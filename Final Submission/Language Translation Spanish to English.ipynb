{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GrK_YEp8B8zU"
   },
   "outputs": [],
   "source": [
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "Z1GWt6QXCB2Y",
    "outputId": "f8b7a674-9b8f-4f39-b67b-486a4c3cf0b8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-2e0aef83-3ebb-419f-b0b2-68df7dbc2793\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-2e0aef83-3ebb-419f-b0b2-68df7dbc2793\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving EnglishNew.txt to EnglishNew (7).txt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-5112fcdc-8aca-4b62-9007-5c579c30d7be\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-5112fcdc-8aca-4b62-9007-5c579c30d7be\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving SpanishNew.txt to SpanishNew (7).txt\n"
     ]
    }
   ],
   "source": [
    "englishtxt = files.upload()\n",
    "spanishtxt = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bI2cPvjqTURr"
   },
   "outputs": [],
   "source": [
    "# spanishtest = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9yWlbOgSTdG_"
   },
   "outputs": [],
   "source": [
    "# temp_esp_txt = [ele.lower() for ele in spanishtest[\"SpanishTest.txt\"].decode(\"utf-8\", \"ignore\").replace(\"\\r\\n\",\".\").split('.')]\n",
    "# esp_txt = []\n",
    "# for ele in temp_esp_txt:\n",
    "#   if len(ele)>3:\n",
    "#     if ele[0]==\" \":\n",
    "#       esp_txt.append(ele[1:])  \n",
    "#       continue\n",
    "#     esp_txt.append(ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yVEA7hF5CEDU"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional, Dropout, LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "cuCAa61BCMGh",
    "outputId": "250b5974-932c-47cf-a464-cd604e5b2aee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7535592162166123059\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 7402421152871166542\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Doh_wBbfCQg8",
    "outputId": "069f4208-ad36-4bbb-94f8-5feb44c57801"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 368,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_sentences = [ele.lower() for ele in englishtxt[\"EnglishNew.txt\"].decode(\"utf-8\", \"ignore\").split('\\r\\n')]\n",
    "\n",
    "len(english_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LflJKSxHCUrv",
    "outputId": "d74b1111-da00-4f6a-a0d8-cf7ca26effca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 369,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spanish_sentences = [ele.lower() for ele in spanishtxt[\"SpanishNew.txt\"].decode(\"utf-8\", \"ignore\").split('\\r\\n')]\n",
    "len(spanish_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "id": "V6FSQEEXCXHL",
    "outputId": "aab85433-0626-436c-dff1-1a6e2720c843"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small_vocab_en Line 1:  cystadenocarcinoma is a rare adenomatous pancreatic cancer that comes from the malignant degeneration of a mucous cystadenoma and is manifested by high abdominal pain and a palpable abdominal mass.\n",
      "small_vocab_esp Line 1:  el cistoadenocarcinoma es un cncer pancretico adenomatoso raro que proviene de la degeneracin maligna de un cistoadenoma mucoso y se manifiesta por dolor abdominal alto y una masa abdominal palpable.\n",
      "\n",
      "small_vocab_en Line 2:  the diagnosis of cystadenocarcinoma is made by ct or mri of the abdomen, which usually shows a cystic mass that contains remains; the mass can be misunderstood as a necrotic adenocarcinoma or a pancreatic pseudocyst.\n",
      "small_vocab_esp Line 2:  el diagnstico del cistadenocarcinoma se realiza por tc o rm de abdomen, que suele mostrar una masa qustica que contiene restos; la masa puede malinterpretarse como un adenocarcinoma necrtico o un seudoquiste pancretico.\n",
      "\n",
      "small_vocab_en Line 3:  unlike ductal adenocarcinoma, cystadenocarcinoma has a relatively good prognosis.\n",
      "small_vocab_esp Line 3:  a diferencia del adenocarcinoma ductal, el cistoadenocarcinoma tiene un pronstico relativamente bueno.\n",
      "\n",
      "small_vocab_en Line 4:  only 20% of patients have metastases at the time of surgery; complete resection of the tumor by distal or total pancreatectomy or by a whipple procedure determines a survival of 65% at 5 years.\n",
      "small_vocab_esp Line 4:  slo el 20% de los pacientes tienen metstasis en el momento de la ciruga; la reseccin completa del tumor por pancreatectoma distal o total o por un procedimiento de whipple determina una supervivencia del 65% a 5 aos.\n",
      "\n",
      "small_vocab_en Line 5:  papillary-mucinous intraductal tumor is a tumor that causes hypersecretion of mucus and ductal obstruction.\n",
      "small_vocab_esp Line 5:  el tumor intraductal papilar-mucinosos es un tumor que causa hipersecrecin de moco y obstruccin ductal.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for sample_i in range(5):\n",
    "    print('small_vocab_en Line {}:  {}'.format(sample_i + 1, english_sentences[sample_i]))\n",
    "    print('small_vocab_esp Line {}:  {}\\n'.format(sample_i + 1, spanish_sentences[sample_i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "tndGH66UCajC",
    "outputId": "ac0218a5-a545-48a1-d992-515bb5f5c5a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2185 English words.\n",
      "924 unique English words.\n",
      "10 Most common words in the English dataset:\n",
      "\"the\" \"of\" \"and\" \"is\" \"to\" \"a\" \"or\" \"in\" \"with\" \"blood\"\n",
      "\n",
      "2538 Spanish words.\n",
      "968 unique Spanish words.\n",
      "10 Most common words in the Spanish dataset:\n",
      "\"de\" \"la\" \"el\" \"y\" \"los\" \"en\" \"a\" \"o\" \"una\" \"se\"\n"
     ]
    }
   ],
   "source": [
    "english_words_counter = collections.Counter([word for sentence in english_sentences for word in sentence.split()])\n",
    "spanish_words_counter = collections.Counter([word for sentence in spanish_sentences for word in sentence.split()])\n",
    "\n",
    "print('{} English words.'.format(len([word for sentence in english_sentences for word in sentence.split()])))\n",
    "print('{} unique English words.'.format(len(english_words_counter)))\n",
    "print('10 Most common words in the English dataset:')\n",
    "print('\"' + '\" \"'.join(list(zip(*english_words_counter.most_common(10)))[0]) + '\"')\n",
    "print()\n",
    "print('{} Spanish words.'.format(len([word for sentence in spanish_sentences for word in sentence.split()])))\n",
    "print('{} unique Spanish words.'.format(len(spanish_words_counter)))\n",
    "print('10 Most common words in the Spanish dataset:')\n",
    "print('\"' + '\" \"'.join(list(zip(*spanish_words_counter.most_common(10)))[0]) + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5cpUF4JyCk11"
   },
   "outputs": [],
   "source": [
    "def tokenize(x):\n",
    "    \"\"\"\n",
    "    Tokenize x\n",
    "    :param x: List of sentences/strings to be tokenized\n",
    "    :return: Tuple of (tokenized x data, tokenizer used to tokenize x)\n",
    "    \"\"\"\n",
    "    # TODO: Implement\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(x)\n",
    "    return tokenizer.texts_to_sequences(x), tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1TRYAO7cDd0v"
   },
   "outputs": [],
   "source": [
    "def pad(x, length=None):\n",
    "    \"\"\"\n",
    "    Pad x\n",
    "    :param x: List of sequences.\n",
    "    :param length: Length to pad the sequence to.  If None, use length of longest sequence in x.\n",
    "    :return: Padded numpy array of sequences\n",
    "    \"\"\"\n",
    "    # TODO: Implement\n",
    "    return pad_sequences(x, maxlen=length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XiGdf7m5Dl8B"
   },
   "outputs": [],
   "source": [
    "def preprocess(x, y):\n",
    "    \"\"\"\n",
    "    Preprocess x and y\n",
    "    :param x: Feature List of sentences\n",
    "    :param y: Label List of sentences\n",
    "    :return: Tuple of (Preprocessed x, Preprocessed y, x tokenizer, y tokenizer)\n",
    "    \"\"\"\n",
    "    preprocess_x, x_tk = tokenize(x)\n",
    "    preprocess_y, y_tk = tokenize(y)\n",
    "    preprocess_x = pad(preprocess_x)\n",
    "    preprocess_y = pad(preprocess_y)\n",
    "\n",
    "    # Keras's sparse_categorical_crossentropy function requires the labels to be in 3 dimensions\n",
    "    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n",
    "\n",
    "    return preprocess_x, preprocess_y, x_tk, y_tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "0X9FhrHnE5zB",
    "outputId": "566e24e1-493a-4357-dccc-55608ceb0ed1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preprocessed\n",
      "Max Spaninsh sentence length: 53\n",
      "Max English sentence length: 46\n",
      "Spaninsh vocabulary size: 841\n",
      "English vocabulary size: 783\n"
     ]
    }
   ],
   "source": [
    "preproc_spanish_sentences, preproc_english_sentences, spanish_tokenizer, english_tokenizer  =\\\n",
    "    preprocess(spanish_sentences, english_sentences)\n",
    "\n",
    "max_spanish_sequence_length = preproc_spanish_sentences.shape[1]\n",
    "max_english_sequence_length = preproc_english_sentences.shape[1]\n",
    "\n",
    "spanish_vocab_size = len(spanish_tokenizer.word_index)\n",
    "english_vocab_size = len(english_tokenizer.word_index)\n",
    "\n",
    "print('Data Preprocessed')\n",
    "print(\"Max Spaninsh sentence length:\", max_spanish_sequence_length)\n",
    "print(\"Max English sentence length:\", max_english_sequence_length)\n",
    "print(\"Spaninsh vocabulary size:\", spanish_vocab_size)\n",
    "print(\"English vocabulary size:\", english_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "j0sPIi9xE6sS",
    "outputId": "dfe9610c-b702-4512-c4db-67fe44200be9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`logits_to_text` function loaded.\n"
     ]
    }
   ],
   "source": [
    "def logits_to_text(logits, tokenizer):\n",
    "    \"\"\"\n",
    "    Turn logits from a neural network into text using the tokenizer\n",
    "    :param logits: Logits from a neural network\n",
    "    :param tokenizer: Keras Tokenizer fit on the labels\n",
    "    :return: String that represents the text of the logits\n",
    "    \"\"\"\n",
    "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
    "    index_to_words[0] = '<PAD>'\n",
    "\n",
    "    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])\n",
    "\n",
    "print('`logits_to_text` function loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FYzhhZwAFMJ1"
   },
   "outputs": [],
   "source": [
    "def bd_model(input_shape, output_sequence_length, spanish_vocab_size, english_vocab_size):\n",
    "    \"\"\"\n",
    "    Build and train a bidirectional RNN model on x and y\n",
    "    :param input_shape: Tuple of input shape\n",
    "    :param output_sequence_length: Length of output sequence\n",
    "    :param english_vocab_size: Number of unique English words in the dataset\n",
    "    :param french_vocab_size: Number of unique French words in the dataset\n",
    "    :return: Keras model built, but not trained\n",
    "    \"\"\"\n",
    "    # TODO: Implement\n",
    "\n",
    "    # Hyperparameters\n",
    "    learning_rate = 0.003\n",
    "    \n",
    "    # TODO: Build the layers\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(GRU(128, return_sequences=True), input_shape=input_shape[1:]))\n",
    "    model.add(TimeDistributed(Dense(512, activation='relu')))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(TimeDistributed(Dense(english_vocab_size, activation='softmax'))) \n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GcJZB690zZwI"
   },
   "outputs": [],
   "source": [
    "# # : Reshape the input\n",
    "# tmp_x = pad(preproc_spanish_sentences, preproc_english_sentences.shape[1])\n",
    "# tmp_x = tmp_x.reshape((-1, preproc_english_sentences.shape[-2], 1))\n",
    "# esp_test = pad(preproc_spanish_sentences[:11], preproc_english_sentences[:11].shape[1])\n",
    "# esp_test = esp_test.reshape((-1, preproc_english_sentences[:11].shape[-2], 1))\n",
    "\n",
    "# # TODO: Train the neural network\n",
    "# bd_rnn_model = bd_model(\n",
    "#     tmp_x.shape,\n",
    "#     preproc_english_sentences[11:].shape[1],\n",
    "#     len(spanish_tokenizer.word_index)+1,\n",
    "#     len(english_tokenizer.word_index)+1)\n",
    "\n",
    "# bd_rnn_model.summary()\n",
    "\n",
    "# bd_rnn_model.fit(tmp_x, preproc_english_sentences, batch_size=7, epochs=30, validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "njLGuipNqKHl",
    "outputId": "27f1282e-2f0b-4e1c-ae9b-47bfac426d54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_22 (Bidirectio (None, 46, 256)           99840     \n",
      "_________________________________________________________________\n",
      "time_distributed_43 (TimeDis (None, 46, 512)           131584    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 46, 512)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_44 (TimeDis (None, 46, 784)           402192    \n",
      "=================================================================\n",
      "Total params: 633,616\n",
      "Trainable params: 633,616\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 99 samples, validate on 6 samples\n",
      "Epoch 1/30\n",
      "99/99 [==============================] - 7s 72ms/step - loss: 4.7371 - acc: 0.5556 - val_loss: 2.9859 - val_acc: 0.5761\n",
      "Epoch 2/30\n",
      "99/99 [==============================] - 1s 14ms/step - loss: 2.6435 - acc: 0.5892 - val_loss: 3.3593 - val_acc: 0.5870\n",
      "Epoch 3/30\n",
      "99/99 [==============================] - 1s 14ms/step - loss: 2.5078 - acc: 0.5916 - val_loss: 3.3569 - val_acc: 0.5797\n",
      "Epoch 4/30\n",
      "99/99 [==============================] - 1s 14ms/step - loss: 2.4282 - acc: 0.5960 - val_loss: 3.4744 - val_acc: 0.5797\n",
      "Epoch 5/30\n",
      "99/99 [==============================] - 1s 14ms/step - loss: 2.3834 - acc: 0.5955 - val_loss: 3.5452 - val_acc: 0.5761\n",
      "Epoch 6/30\n",
      "99/99 [==============================] - 1s 14ms/step - loss: 2.3228 - acc: 0.5975 - val_loss: 3.7047 - val_acc: 0.5797\n",
      "Epoch 7/30\n",
      "99/99 [==============================] - 1s 13ms/step - loss: 2.2876 - acc: 0.5971 - val_loss: 3.8536 - val_acc: 0.5725\n",
      "Epoch 8/30\n",
      "99/99 [==============================] - 1s 14ms/step - loss: 2.2522 - acc: 0.5968 - val_loss: 3.8699 - val_acc: 0.5833\n",
      "Epoch 9/30\n",
      "99/99 [==============================] - 1s 14ms/step - loss: 2.1874 - acc: 0.5984 - val_loss: 3.8921 - val_acc: 0.5833\n",
      "Epoch 10/30\n",
      "99/99 [==============================] - 1s 14ms/step - loss: 2.1455 - acc: 0.6004 - val_loss: 4.1084 - val_acc: 0.5761\n",
      "Epoch 11/30\n",
      "99/99 [==============================] - 1s 14ms/step - loss: 2.0810 - acc: 0.6028 - val_loss: 4.2471 - val_acc: 0.5761\n",
      "Epoch 12/30\n",
      "99/99 [==============================] - 1s 14ms/step - loss: 2.0077 - acc: 0.6028 - val_loss: 4.3905 - val_acc: 0.5797\n",
      "Epoch 13/30\n",
      "99/99 [==============================] - 1s 13ms/step - loss: 1.9628 - acc: 0.6036 - val_loss: 4.4885 - val_acc: 0.5797\n",
      "Epoch 14/30\n",
      "99/99 [==============================] - 1s 14ms/step - loss: 1.8911 - acc: 0.6052 - val_loss: 4.5438 - val_acc: 0.5725\n",
      "Epoch 15/30\n",
      "99/99 [==============================] - 1s 14ms/step - loss: 1.8201 - acc: 0.6137 - val_loss: 4.6352 - val_acc: 0.5761\n",
      "Epoch 16/30\n",
      "99/99 [==============================] - 1s 14ms/step - loss: 1.8989 - acc: 0.6087 - val_loss: 4.5952 - val_acc: 0.5797\n",
      "Epoch 17/30\n",
      "99/99 [==============================] - 1s 14ms/step - loss: 1.8420 - acc: 0.6146 - val_loss: 4.6101 - val_acc: 0.5797\n",
      "Epoch 18/30\n",
      "99/99 [==============================] - 1s 14ms/step - loss: 1.7248 - acc: 0.6258 - val_loss: 4.6649 - val_acc: 0.5833\n",
      "Epoch 19/30\n",
      "99/99 [==============================] - 1s 14ms/step - loss: 1.6718 - acc: 0.6322 - val_loss: 4.6560 - val_acc: 0.5797\n",
      "Epoch 20/30\n",
      "99/99 [==============================] - 1s 14ms/step - loss: 1.5782 - acc: 0.6440 - val_loss: 4.8039 - val_acc: 0.5761\n",
      "Epoch 21/30\n",
      "99/99 [==============================] - 1s 14ms/step - loss: 1.5479 - acc: 0.6559 - val_loss: 4.7300 - val_acc: 0.5725\n",
      "Epoch 22/30\n",
      "99/99 [==============================] - 1s 14ms/step - loss: 1.4299 - acc: 0.6750 - val_loss: 4.8527 - val_acc: 0.5797\n",
      "Epoch 23/30\n",
      "99/99 [==============================] - 1s 14ms/step - loss: 1.3609 - acc: 0.6858 - val_loss: 4.8348 - val_acc: 0.5761\n",
      "Epoch 24/30\n",
      "99/99 [==============================] - 1s 14ms/step - loss: 1.3045 - acc: 0.7016 - val_loss: 4.9130 - val_acc: 0.5725\n",
      "Epoch 25/30\n",
      "99/99 [==============================] - 1s 14ms/step - loss: 1.2696 - acc: 0.7016 - val_loss: 4.9338 - val_acc: 0.5761\n",
      "Epoch 26/30\n",
      "99/99 [==============================] - 1s 14ms/step - loss: 1.1758 - acc: 0.7268 - val_loss: 4.9720 - val_acc: 0.5761\n",
      "Epoch 27/30\n",
      "99/99 [==============================] - 1s 14ms/step - loss: 1.1039 - acc: 0.7398 - val_loss: 4.9637 - val_acc: 0.5797\n",
      "Epoch 28/30\n",
      "99/99 [==============================] - 1s 14ms/step - loss: 1.0607 - acc: 0.7473 - val_loss: 5.0311 - val_acc: 0.5761\n",
      "Epoch 29/30\n",
      "99/99 [==============================] - 1s 14ms/step - loss: 1.0018 - acc: 0.7646 - val_loss: 4.9698 - val_acc: 0.5797\n",
      "Epoch 30/30\n",
      "99/99 [==============================] - 1s 14ms/step - loss: 0.9645 - acc: 0.7679 - val_loss: 5.0199 - val_acc: 0.5761\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fba8566ce10>"
      ]
     },
     "execution_count": 379,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Reshape the input\n",
    "tmp_x = pad(preproc_spanish_sentences[11:], preproc_english_sentences[11:].shape[1])\n",
    "tmp_x = tmp_x.reshape((-1, preproc_english_sentences[11:].shape[-2], 1))\n",
    "esp_test = pad(preproc_spanish_sentences[:11], preproc_english_sentences[:11].shape[1])\n",
    "esp_test = esp_test.reshape((-1, preproc_english_sentences[:11].shape[-2], 1))\n",
    "\n",
    "# TODO: Train the neural network\n",
    "bd_rnn_model = bd_model(\n",
    "    tmp_x.shape,\n",
    "    preproc_english_sentences[11:].shape[1],\n",
    "    len(spanish_tokenizer.word_index)+1,\n",
    "    len(english_tokenizer.word_index)+1)\n",
    "\n",
    "bd_rnn_model.summary()\n",
    "\n",
    "bd_rnn_model.fit(tmp_x, preproc_english_sentences[11:], batch_size=7, epochs=30, validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "M8k0WldFRzS6",
    "outputId": "b7e3f26f-097c-4918-c654-85355b436dbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if cancer be of given prompt of any it or termination 2 to 1 to output measured after fetus 4 once once in <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "other gestational patients no an to have bile to specific or pruritus to be disease years to 1 and to obstructive 1 accessible ee or in 20 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "transfusions involve should delivery delivery as be <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "the on given given within maternal measurement high about and to the to bile bile episode termination to failure indicating measurement of heart an to output failure heart to orally <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "this that for for for for placement duct not systems <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "weight is is and <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "if if or is 80 leading and of to forego complications <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "percutaneous titers splanchnic by or iv epidural force to <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "patients 90 women an that prior tumors to have prior severe to of for to doses 24 the <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "pancreas associated antigen develop when develop develop out critical blood a a develop middle to critical value to or a 2 to known 8 to 1 to maternal given to <PAD> fetal 20 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "about 80 of delivery have unresectable duct sensitization is to 7 and because to orally in <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "esp_txt_len = esp_test.shape[0] \n",
    "for i_esp_txt in range(esp_txt_len):\n",
    "  # Print prediction(s)\n",
    "#   print(\"\\nPrediction:\")\n",
    "  print(logits_to_text(bd_rnn_model.predict(esp_test[i_esp_txt:i_esp_txt+1])[0], english_tokenizer))\n",
    "#   print(\"\\nCorrect Translation:\")\n",
    "#   print(english_sentences[i_esp_txt:i_esp_txt+1])\n",
    "\n",
    "#   print(\"\\nOriginal text:\")\n",
    "#   print(spanish_sentences[i_esp_txt:i_esp_txt+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y-BPgktD9mx1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3OU_tOfY9nL_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Esp2Eng",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
